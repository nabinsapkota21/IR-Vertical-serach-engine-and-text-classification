{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "steady-local",
   "metadata": {},
   "source": [
    "# Information Retrieval Coursework (7071CEM)\n",
    "\n",
    "Task:\n",
    "Whether as a separate program or integrated with search engine, a subject classification functionality is needed.\n",
    "\n",
    "This program implements a text classifier using a NLP techniques and a selection of classification algorithms.\n",
    "\n",
    "Based on the datasets sourced, the three chosen classifications are:\n",
    "\n",
    "* Business\n",
    "* health\n",
    "* sports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pressed-gateway",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "second-memphis",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T01:59:41.760225Z",
     "start_time": "2021-08-01T01:59:41.515144Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import string\n",
    "\n",
    "# Data Handling and Processing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from scipy import interp\n",
    "\n",
    "# Visualuzation\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "\n",
    "# NLP Packages\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import pos_tag\n",
    "import nltk\n",
    "from joblib import dump, load\n",
    "\n",
    "# ML Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Scikit Learn packages\n",
    "from sklearn.base import clone\n",
    "from sklearn.preprocessing import label_binarize, LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.model_selection import KFold, cross_validate, cross_val_score, train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, auc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indonesian-postage",
   "metadata": {},
   "source": [
    "# Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "familiar-history",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T01:42:07.905926Z",
     "start_time": "2021-08-01T01:42:07.816237Z"
    }
   },
   "outputs": [],
   "source": [
    "text_df = pd.DataFrame(columns=['Text','Class'])\n",
    "text_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "german-confidence",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T01:45:35.332747Z",
     "start_time": "2021-08-01T01:43:42.973811Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function to read the text files into one dataframe\n",
    "def readfiles_to_dataframe(directory, category):\n",
    "    arr = os.listdir(directory)\n",
    "    strtext = \".txt\"\n",
    "    for textfile in arr:\n",
    "        if textfile.__contains__(strtext):\n",
    "            fileObject = open(directory + textfile, \"r\")\n",
    "            data = fileObject.read()\n",
    "            ouvert = pd.read_csv('news.csv', index_col=\"Unnamed: 0\")\n",
    "            ouvert = ouvert.append({\"Class\": str(category), \"Text\": data},ignore_index=True)\n",
    "            ouvert.to_csv('news.csv')   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "flush-consolidation",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T01:45:56.821008Z",
     "start_time": "2021-08-01T01:45:56.763186Z"
    }
   },
   "outputs": [],
   "source": [
    "full_df = pd.read_csv('news.csv')\n",
    "print(full_df.shape)\n",
    "full_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "after-prevention",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T01:46:13.096704Z",
     "start_time": "2021-08-01T01:46:13.039953Z"
    }
   },
   "outputs": [],
   "source": [
    "full_df.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "full_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nonprofit-syndication",
   "metadata": {},
   "source": [
    "## 1. Dataset Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "great-nightlife",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T02:02:06.282040Z",
     "start_time": "2021-08-01T02:02:06.032043Z"
    }
   },
   "outputs": [],
   "source": [
    "full_df['Class'].value_counts().plot(kind='pie')\n",
    "plt.title('Number of News articles per Category', size=20, pad=20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subsequent-hometown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T02:02:39.543408Z",
     "start_time": "2021-08-01T02:02:39.514242Z"
    }
   },
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "full_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "naughty-samba",
   "metadata": {},
   "source": [
    "## 2. Text Preprocessing\n",
    "\n",
    "Here, unwanted parts of the text are removed such as special characters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "major-springer",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T02:05:41.825096Z",
     "start_time": "2021-08-01T02:05:41.787802Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess(df):\n",
    "    # Remove special characters\n",
    "    df['Text2'] = df['Text'].replace('\\n',' ')\n",
    "    df['Text2'] = df['Text2'].replace('\\r',' ')\n",
    "    \n",
    "    # Remove punctuation signs and lowercase all\n",
    "    df['Text2'] = df['Text2'].str.lower()\n",
    "    df['Text2'] = df['Text2'].str.translate(str.maketrans('', '', string.punctuation))\n",
    "    \n",
    "    # Remove stop words\n",
    "    stop_words = stopwords.words(\"english\")\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    def fwpt(each):\n",
    "        tag = pos_tag([each])[0][1][0].upper()\n",
    "        hash_tag = {\"N\": wordnet.NOUN,\"R\": wordnet.ADV, \"V\": wordnet.VERB,\"J\": wordnet.ADJ}        \n",
    "        return hash_tag.get(tag, wordnet.NOUN)\n",
    "\n",
    "    def lematize(text):\n",
    "        tokens = nltk.word_tokenize(text)\n",
    "        ax = \"\"\n",
    "        for each in tokens:\n",
    "            if each not in stop_words:\n",
    "                ax += lemmatizer.lemmatize(each, fwpt(each)) + \" \"\n",
    "        return ax\n",
    "    \n",
    "    df['Text2'] = df['Text2'].apply(lematize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subtle-floating",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T02:08:25.551690Z",
     "start_time": "2021-08-01T02:07:24.370175Z"
    }
   },
   "outputs": [],
   "source": [
    "preprocess(full_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opposite-baltimore",
   "metadata": {},
   "source": [
    "### Demonstration of Preprocessing\n",
    "\n",
    "**Original:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informal-disease",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T02:09:19.409252Z",
     "start_time": "2021-08-01T02:09:19.402659Z"
    }
   },
   "outputs": [],
   "source": [
    "full_df.iloc[1]['Text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continent-teddy",
   "metadata": {},
   "source": [
    "**Processed:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incoming-chemical",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T02:10:20.041432Z",
     "start_time": "2021-08-01T02:10:20.031098Z"
    }
   },
   "outputs": [],
   "source": [
    "full_df.iloc[1]['Text2']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rolled-chancellor",
   "metadata": {},
   "source": [
    "## 3. Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "miniature-crime",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T02:19:53.776543Z",
     "start_time": "2021-08-01T02:19:53.695104Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(full_df['Text2'], \n",
    "                                                    full_df['Class'], \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conceptual-specification",
   "metadata": {},
   "source": [
    "#### Check for acceptable category balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "modular-discount",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T02:23:04.756438Z",
     "start_time": "2021-08-01T02:23:04.493698Z"
    }
   },
   "outputs": [],
   "source": [
    "y_train.value_counts().plot(kind='pie')\n",
    "plt.title('Category Balance', size=25, pad=25);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "structural-timeline",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T02:23:54.357909Z",
     "start_time": "2021-08-01T02:23:54.341711Z"
    }
   },
   "outputs": [],
   "source": [
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "theoretical-payment",
   "metadata": {},
   "source": [
    "## 4.  Vectorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "present-company",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T02:24:58.293184Z",
     "start_time": "2021-08-01T02:24:58.262149Z"
    }
   },
   "outputs": [],
   "source": [
    "vector = TfidfVectorizer(stop_words='english', \n",
    "                         ngram_range = (1,2),\n",
    "                         min_df = 3,\n",
    "                         max_df = 1.,\n",
    "                         max_features = 10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "progressive-detroit",
   "metadata": {},
   "source": [
    "## 5.  Construct Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "natural-louis",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T02:30:47.223623Z",
     "start_time": "2021-08-01T02:30:47.193232Z"
    }
   },
   "outputs": [],
   "source": [
    "def fit_model(model, model_name):\n",
    "    line = Pipeline([('vectorize', vector), (model_name, model)])\n",
    "    \n",
    "    output = cross_validate(line, \n",
    "                            X_train, \n",
    "                            y_train, \n",
    "                            cv = KFold(shuffle = True, \n",
    "                                       n_splits = 3,  \n",
    "                                       random_state = 9),\n",
    "                            scoring = ('accuracy', 'f1_weighted','precision_weighted','recall_weighted'),           \n",
    "                            return_train_score=True)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reasonable-inspector",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T02:31:41.443274Z",
     "start_time": "2021-08-01T02:31:29.795635Z"
    }
   },
   "outputs": [],
   "source": [
    "dectree = fit_model(DecisionTreeClassifier(), 'DTree')\n",
    "ridge = fit_model(RidgeClassifier(), 'Ridge')\n",
    "bayes = fit_model(MultinomialNB(), 'NB')\n",
    "\n",
    "dt = pd.DataFrame.from_dict(dectree)\n",
    "rc = pd.DataFrame.from_dict(ridge)\n",
    "bc = pd.DataFrame.from_dict(bayes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compressed-contractor",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T02:32:19.672291Z",
     "start_time": "2021-08-01T02:32:19.642518Z"
    }
   },
   "outputs": [],
   "source": [
    "l1 = [bc, rc, dt]\n",
    "l2 =[\"NB\", \"Ridge\", \"DT\"]\n",
    "\n",
    "for each, tag in zip(l1, l2):\n",
    "    each['model'] = [tag, tag, tag]\n",
    "\n",
    "joined_output = pd.concat([bc,rc,dt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "automatic-device",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T02:33:12.025271Z",
     "start_time": "2021-08-01T02:33:12.016908Z"
    }
   },
   "outputs": [],
   "source": [
    "dectree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worth-marijuana",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T02:33:21.177196Z",
     "start_time": "2021-08-01T02:33:21.168888Z"
    }
   },
   "outputs": [],
   "source": [
    "ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cleared-romania",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T02:33:33.009773Z",
     "start_time": "2021-08-01T02:33:33.001230Z"
    }
   },
   "outputs": [],
   "source": [
    "bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elect-trail",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T02:34:09.787789Z",
     "start_time": "2021-08-01T02:34:09.744308Z"
    }
   },
   "outputs": [],
   "source": [
    "relevant_measures = list(['test_accuracy','test_precision_weighted', 'test_recall_weighted', 'test_f1_weighted'])\n",
    "\n",
    "dec_tree_metrics = joined_output.loc[joined_output.model == 'DT'][relevant_measures]\n",
    "nb_metrics = joined_output.loc[joined_output.model == 'NB'][relevant_measures]\n",
    "r_metrics = joined_output.loc[joined_output.model == 'Ridge'][relevant_measures]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "entitled-pharmacy",
   "metadata": {},
   "source": [
    "#### Decision Tree metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proud-movement",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T02:34:45.966238Z",
     "start_time": "2021-08-01T02:34:45.956440Z"
    }
   },
   "outputs": [],
   "source": [
    "dec_tree_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quality-aspect",
   "metadata": {},
   "source": [
    "#### Multinomial Naive Bayes metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lucky-chance",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T02:35:22.423739Z",
     "start_time": "2021-08-01T02:35:22.412406Z"
    }
   },
   "outputs": [],
   "source": [
    "nb_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "identified-tragedy",
   "metadata": {},
   "source": [
    "#### Ridge Classifier metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "balanced-spain",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T02:36:04.986734Z",
     "start_time": "2021-08-01T02:36:04.976516Z"
    }
   },
   "outputs": [],
   "source": [
    "r_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greenhouse-minutes",
   "metadata": {},
   "source": [
    "#### Average metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stainless-composite",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T02:39:58.060999Z",
     "start_time": "2021-08-01T02:39:58.049490Z"
    }
   },
   "outputs": [],
   "source": [
    "metrics_ = [dec_tree_metrics, nb_metrics, r_metrics]\n",
    "names_ = ['Decision Tree', 'Naive Bayes', 'Ridge Classifier']\n",
    "\n",
    "for scores, namess in zip(metrics_, names_):\n",
    "    print(f'{namess} Mean Metrics:')\n",
    "    print(scores.mean())\n",
    "    print('  ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "polish-speaking",
   "metadata": {},
   "source": [
    "### Selection of Model\n",
    "From the metrics obtained above, we see that **Ridge Classifier** performs best. However, the **Multinomial Naive Bayes classifier** is chosen to create the final model.\n",
    "\n",
    "This is because it **has the ability to provide probability score** for each prediction it makes, while scoring similarly to the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dense-guyana",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T02:44:16.662468Z",
     "start_time": "2021-08-01T02:44:16.580681Z"
    }
   },
   "outputs": [],
   "source": [
    "# Join training and test datasets\n",
    "X = pd.concat([X_train, \n",
    "               X_test])\n",
    "y = pd.concat([y_train, \n",
    "               y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "british-sydney",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T02:44:29.080314Z",
     "start_time": "2021-08-01T02:44:29.044334Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_and_fit(clf, x, y):\n",
    "    best_clf = clf\n",
    "    pipeline = Pipeline([('vectorize', vector), ('model', best_clf)])\n",
    "    return pipeline.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stock-irish",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T02:45:18.860042Z",
     "start_time": "2021-08-01T02:45:17.006039Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create model\n",
    "CLASSYfier = create_and_fit(MultinomialNB(), X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "united-syndication",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T02:45:44.869993Z",
     "start_time": "2021-08-01T02:45:44.846627Z"
    }
   },
   "outputs": [],
   "source": [
    "CLASSYfier.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "differential-substance",
   "metadata": {},
   "source": [
    "## FINAL TESTING:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "external-reminder",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T02:47:36.005810Z",
     "start_time": "2021-08-01T02:47:35.960191Z"
    }
   },
   "outputs": [],
   "source": [
    "input_text = '(Reuters) -Netflix Inc said it would make a deeper dive into video games as the movie and TV streaming service projected weak subscriber growth amid growing competition and the lifting of pandemic restrictions that had kept people at home.'\n",
    "CLASSYfier.predict_proba([input_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "headed-render",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T03:14:11.710315Z",
     "start_time": "2021-08-01T03:14:11.693640Z"
    }
   },
   "outputs": [],
   "source": [
    "CLASSYfier.predict([input_text])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "champion-found",
   "metadata": {},
   "source": [
    "Interestingly, since the streaming services are also businesses, the model reflects this with a `0.39` probability for the business category."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mediterranean-diamond",
   "metadata": {},
   "source": [
    "## GUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "military-sense",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T22:54:14.333183Z",
     "start_time": "2021-08-01T22:40:20.981984Z"
    }
   },
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter.scrolledtext import ScrolledText\n",
    "\n",
    "window = tk.Tk()\n",
    "window.configure(bg='#98AFC7') \n",
    "window.title(\"IR SUBJECT CLASSIFIER\")\n",
    "window.minsize(600,400)\n",
    "text_box = ScrolledText(window)\n",
    "text_box.grid(column=0, row=1, padx=5, pady=5)\n",
    "\n",
    "def result(res, pr):\n",
    "    BUSINESS = round(pr[0][0], 3)\n",
    "    HEALTH = round(pr[0][1], 3)\n",
    "    SPORTS = round(pr[0][2], 3)\n",
    "    \n",
    "    lines = [f\"Business: {BUSINESS}\" , f\"Health: {HEALTH}\", f\"Sports: {SPORTS}\"]\n",
    "    tk.messagebox.showinfo(message= f\"Predicted Category: {str(res).capitalize()}\" + \"\\n\\n\\n\"+\"\\n\".join(lines))\n",
    "\n",
    "def clickMe():\n",
    "    classification = tk.StringVar()\n",
    "    category_,probabilities = classify_text(text_box.get(\"1.0\",tk.END))\n",
    "    result(category_, probabilities)\n",
    "    \n",
    "def classify_text(input_text):\n",
    "    out = CLASSYfier.predict([input_text])[0]\n",
    "    probs = CLASSYfier.predict_proba([input_text])\n",
    "    return out,probs\n",
    "\n",
    "label = tk.Label(window, text = \"Please enter the text\", bg=\"#87CEFA\",font=(\"Cambria\", 15))\n",
    "label.grid(column = 0, row = 0)\n",
    "\n",
    "btn = tk.Button(window, text=\"Classify\",font=(\"Cambria\", 12), bg=\"#87CEFA\", command=clickMe)\n",
    "btn.grid(column=0, row=2)\n",
    "   \n",
    "window.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exposed-hayes",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e7165bbf",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "processed-wilson",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
